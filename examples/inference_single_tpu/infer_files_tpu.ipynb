{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running inference on a Model\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This page outlines the steps to run inference a model with T5X on Tasks/Mixtures\n",
    "defined with [SeqIO](https://github.com/google/seqio/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Running inference on a model with T5X using SeqIO Task/Mixtures consists of the\n",
    "following steps:\n",
    "\n",
    "1.  Choose the model to run inference on.\n",
    "1.  Choose the SeqIO Task/Mixture to run inference on.\n",
    "1.  Write a Gin file that configures the model, SeqIO Task/Mixture and other\n",
    "    details of your inference run.\n",
    "1.  Launch your experiment on Vertex AI.\n",
    "1.  Monitor your experiment and access predictions.\n",
    "\n",
    "These steps are explained in detail in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and launch a Vertex AI Training job to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project definitions\n",
    "PROJECT_ID = 'renatoleite-dev' # Change to your project id.\n",
    "REGION = 'us-central1'  # Change to your region.\n",
    "\n",
    "# Bucket definitions\n",
    "BUCKET = 'rl-language' # Change to your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket definitions\n",
    "VERSION = 'v01'\n",
    "INFER_NAME = 'infer-wmt-en-de'\n",
    "INFER_DISPLAY_NAME = f'{INFER_NAME}-{VERSION}'\n",
    "\n",
    "# Staging bucket for Vertex AI\n",
    "WORKSPACE = f'gs://{BUCKET}/{INFER_DISPLAY_NAME}'\n",
    "\n",
    "# Docker definitions for training\n",
    "IMAGE_NAME = 't5x-base'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Model dir to save logs, ckpts, etc.\n",
    "INFER_DIR = f'gs://{BUCKET}/infer/{INFER_DISPLAY_NAME}/{TIMESTAMP}'\n",
    "\n",
    "# Data dir to save the processed dataset\n",
    "TFDS_DATA_DIR = f'gs://{BUCKET}/dataset/{INFER_DISPLAY_NAME}'\n",
    "\n",
    "# Gin file and run mode\n",
    "GIN_FILE = 'base_wmt_infer.gin'\n",
    "GIN_FILE_GCS = f'gs://{BUCKET}/staging/{GIN_FILE}'\n",
    "RUN_MODE = 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://base_wmt_infer.gin [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  578.0 B/  578.0 B]                                                \n",
      "Operation completed over 1 objects/578.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "# Copy gin file to GCS bucket and use the local GCSFuse mount\n",
    "! gsutil cp {GIN_FILE} {GIN_FILE_GCS}\n",
    "GIN_FILE_GCS = GIN_FILE_GCS.replace('gs://', '/gcs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Vertex AI client and log metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = f'{INFER_DISPLAY_NAME}-{TIMESTAMP}'\n",
    "EXECUTION_NAME = f'execution-1'\n",
    "RUN_NAME = 'run-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=f'gs://{BUCKET}/staging',\n",
    "    experiment=EXPERIMENT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/375468928805/locations/us-central1/metadataStores/default/contexts/infer-wmt-en-de-v01-202207221327-run-1 to Experiment: infer-wmt-en-de-v01-202207221327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.experiment_run_resource.ExperimentRun at 0x7f21b5a1e550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_ai.start_run(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with vertex_ai.start_execution(\n",
    "    schema_title=\"system.ContainerExecution\", display_name=EXECUTION_NAME\n",
    ") as execution:\n",
    "\n",
    "    dataset_seqio_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Dataset\", \n",
    "        display_name='infer_dataset',\n",
    "        metadata= {\n",
    "            'split': 'test',\n",
    "            'task': 'wmt_t2t_translate'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with open(GIN_FILE) as fp:\n",
    "        gin_content = fp.read()\n",
    "\n",
    "    gin_config_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Artifact\", \n",
    "        display_name='gin_configuration_file', \n",
    "        uri=GIN_FILE_GCS.replace('/gcs/', 'gs://'),\n",
    "        metadata= {\n",
    "            'gin_file': gin_content\n",
    "        }\n",
    "    )\n",
    "\n",
    "    infer_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Artifact\", \n",
    "        display_name='infer_wmt_finetuned_model', \n",
    "        uri=INFER_DIR\n",
    "    )\n",
    "\n",
    "    execution.assign_input_artifacts([dataset_seqio_artifact, gin_config_artifact])\n",
    "    execution.assign_output_artifacts([infer_artifact])\n",
    "\n",
    "    vertex_ai.log_metrics(\n",
    "        {\"lineage\": execution.get_output_artifacts()[0].lineage_console_uri}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define infra and submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'cloud-tpu'\n",
    "ACCELERATOR_TYPE = 'TPU_V2'\n",
    "ACCELERATOR_NUM = 8\n",
    "REPLICA_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": REPLICA_COUNT,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"args\": [\n",
    "                f'--run_mode={RUN_MODE}',\n",
    "                f'--gin_file={GIN_FILE_GCS}',\n",
    "                f'--gin.INFER_OUTPUT_DIR=\"{INFER_DIR}\"',\n",
    "                f'--tfds_data_dir={TFDS_DATA_DIR}',\n",
    "                '--gin.USE_CACHED_TASKS=False'\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n"
     ]
    }
   ],
   "source": [
    "job_name = 't5x_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir =  os.path.join(WORKSPACE, job_name)\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    sync=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
