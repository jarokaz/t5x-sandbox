{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train a Translation Model with T5X on Vertex AI TPU Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Configure and launch a Vertex AI Training job to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project definitions\n",
    "PROJECT_ID = 'jk-mlops-dev' # Change to your project id.\n",
    "REGION = 'us-central1'  # Change to your region.\n",
    "\n",
    "# Bucket definitions\n",
    "BUCKET = 'rl-mlops-language' # Change to your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket definitions\n",
    "VERSION = 'v01'\n",
    "MODEL_NAME = 'pretrain-en-de'\n",
    "MODEL_DISPLAY_NAME = f'{MODEL_NAME}-{VERSION}'\n",
    "\n",
    "# Staging bucket for Vertex AI\n",
    "WORKSPACE = f'gs://{BUCKET}/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Docker definitions for training\n",
    "IMAGE_NAME = 't5x-base'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Model dir to save logs, ckpts, etc.\n",
    "MODEL_DIR = f'gs://{BUCKET}/model/{MODEL_DISPLAY_NAME}/{TIMESTAMP}'\n",
    "\n",
    "# Data dir to save the processed dataset\n",
    "TFDS_DATA_DIR = f'gs://{BUCKET}/dataset/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Gin file and run mode\n",
    "GIN_FILE = 'wmt19_ende_from_scratch.gin'\n",
    "GIN_FILE_GCS = f'gs://{BUCKET}/staging/{GIN_FILE}'\n",
    "RUN_MODE = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://wmt19_ende_from_scratch.gin [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.5 KiB/  1.5 KiB]                                                \n",
      "Operation completed over 1 objects/1.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Copy gin file to GCS bucket and use the local GCSFuse mount\n",
    "! gsutil cp {GIN_FILE} {GIN_FILE_GCS}\n",
    "GIN_FILE_GCS = GIN_FILE_GCS.replace('gs://', '/gcs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Vertex AI client and log metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = f'{MODEL_DISPLAY_NAME}-{TIMESTAMP}'\n",
    "EXECUTION_NAME = f'execution-1'\n",
    "RUN_NAME = 'run-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=f'gs://{BUCKET}/staging',\n",
    "    experiment=EXPERIMENT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/895222332033/locations/us-central1/metadataStores/default/contexts/pretrain-en-de-v01-202207221528-run-1 to Experiment: pretrain-en-de-v01-202207221528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.experiment_run_resource.ExperimentRun at 0x7efc4dac0a10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_ai.start_run(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with vertex_ai.start_execution(\n",
    "    schema_title=\"system.ContainerExecution\", display_name=EXECUTION_NAME\n",
    ") as execution:\n",
    "\n",
    "    dataset_seqio_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Dataset\", display_name='tfds_dataset', uri=TFDS_DATA_DIR\n",
    "    )\n",
    "\n",
    "    with open(GIN_FILE) as fp:\n",
    "        gin_content = fp.read()\n",
    "\n",
    "    gin_config_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Artifact\", \n",
    "        display_name='gin_configuration_file', \n",
    "        uri=GIN_FILE_GCS.replace('/gcs/', 'gs://'),\n",
    "        metadata= {\n",
    "            'gin_file': gin_content\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_artifact = vertex_ai.Artifact.create(\n",
    "        schema_title=\"system.Model\", display_name='wmt_pretrained_model', uri=MODEL_DIR\n",
    "    )\n",
    "\n",
    "    execution.assign_input_artifacts([dataset_seqio_artifact, gin_config_artifact])\n",
    "    execution.assign_output_artifacts([model_artifact])\n",
    "\n",
    "    vertex_ai.log_metrics(\n",
    "        {\"lineage\": execution.get_output_artifacts()[0].lineage_console_uri}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define infra and submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'cloud-tpu'\n",
    "ACCELERATOR_TYPE = 'TPU_V2'\n",
    "ACCELERATOR_NUM = 32\n",
    "REPLICA_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": REPLICA_COUNT,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"args\": [\n",
    "                f'--run_mode={RUN_MODE}',\n",
    "                f'--gin_file={GIN_FILE_GCS}',\n",
    "                f'--gin.MODEL_DIR=\"{MODEL_DIR}\"',\n",
    "                f'--tfds_data_dir={TFDS_DATA_DIR}',\n",
    "                '--gin.USE_CACHED_TASKS=False'\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n"
     ]
    }
   ],
   "source": [
    "job_name = 't5x_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir =  os.path.join(WORKSPACE, job_name)\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Explore metrics\n",
    "\n",
    "After fine-tuning has completed, you can parse metrics into CSV format using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_VAL_DIR=f'gs://{BUCKET}/model/{MODEL_DISPLAY_NAME}/inference_eval/*'\n",
    "VAL_DIR = './inference_eval'\n",
    "OUTPUT_FILE = './results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir {VAL_DIR}\n",
    "! gsutil -m cp -r {GCS_VAL_DIR} {VAL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m t5.scripts.parse_tb \\\n",
    "  --summary_dir={VAL_DIR} \\\n",
    "  --seqio_summaries \\\n",
    "  --out_file={OUTPUT_FILE} \\\n",
    "  --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results.csv', sep=',')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['max_squad_em'] = results[-2:-1]['SQuAD (EM)'].values[0]\n",
    "metrics['max_squad_f1'] = results[-2:-1]['SQuAD (F1)'].values[0]\n",
    "metrics['step_squad_em'] = results[-1:]['SQuAD (EM)'].values[0]\n",
    "metrics['step_squad_f1'] = results[-1:]['SQuAD (F1)'].values[0]\n",
    "vertex_ai.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse with Vertex AI Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_INSTANCE_NAME = 't5x-analyse'\n",
    "VALIDATION_TB_LOGS = f'gs://{BUCKET}/model/{MODEL_DISPLAY_NAME}/inference_eval'\n",
    "TRAINING_TB_LOGS = f'gs://{BUCKET}/model/{MODEL_DISPLAY_NAME}/training_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud ai tensorboards create --display-name={TENSORBOARD_INSTANCE_NAME} --region={REGION} --project={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_id = ! gcloud ai tensorboards list --filter=\"displayName=t5x-analyse\" --format=\"value(name)\" --region=us-central1 --limit=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tb-gcp-uploader --tensorboard_resource_name \\\n",
    "  {tensorboard_id[1]} \\\n",
    "  --logdir={VALIDATION_TB_LOGS} \\\n",
    "  --experiment_name={EXPERIMENT_ID} --one_shot=True\n",
    "\n",
    "! tb-gcp-uploader --tensorboard_resource_name \\\n",
    "  {tensorboard_id[1]} \\\n",
    "  --logdir={TRAINING_TB_LOGS} \\\n",
    "  --experiment_name={EXPERIMENT_ID} --one_shot=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open the URL presented in the output of this command and analyse the training and inference logs.\n",
    "\n",
    "![Tensorboard](./images/tb-sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Explanations\n",
    "\n",
    "By default, t5x logs many metrics to TensorBoard, many of these seem similar but\n",
    "have important distinctions.\n",
    "\n",
    "The first two graphs you will see are the `accuracy` and `cross_ent_loss`\n",
    "graphs. These are the *token-level teacher-forced* accuracy and cross entropy\n",
    "loss respectively. Each of these graphs can have multiple curves on them. The\n",
    "first curve is the `train` curve. This is calculated as a running sum than is\n",
    "then normalized over the whole training set. The second class of curves have the\n",
    "form `training_eval/${task_name}`. These curves are created by running a subset\n",
    "(controlled by the `eval_steps` parameter of the main train function) of the\n",
    "validation split of `${task_name}` through the model and calculating these\n",
    "metrics using teacher-forcing. These graphs can commonly be used to find\n",
    "\"failure to learn\" cases and as a warning sign of overfitting, but these are\n",
    "often not the final metrics one would report on.\n",
    "\n",
    "The second set of graphs are the ones under the collapsible `eval` section in\n",
    "TensorBoard. These graphs are created based on the `metric_fns` defined in the\n",
    "SeqIO task. The curves on these graphs have the form\n",
    "`inference_eval/${task_name}`. Values are calculated by running the whole\n",
    "validation split through the model in inference mode, commonly auto-regressive\n",
    "decoding or output scoring. Most likely these are the metrics that will be\n",
    "reported.\n",
    "\n",
    "More information about the configuration of the datasets used for these\n",
    "different metrics can be found [here](#train-train-eval-and-infer-eval).\n",
    "\n",
    "In summary, the metric you actually care about most likely lives under the\n",
    "`eval` tab rather, than in the `accuracy` graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
