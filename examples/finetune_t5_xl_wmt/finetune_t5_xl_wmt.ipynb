{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning T5 1.1 XL on WMT task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev' # Change to your project id.\n",
    "REGION = 'us-central1'  # Change to your region.\n",
    "BUCKET = 'jk-t5x-staging' # Change to your bucket.\n",
    "TENSORBOARD_NAME = '\n",
    "TENSORBOARD_ID = ! gcloud ai tensorboards list --filter=\"displayName={TENSORBOARD_NAME}\" --format=\"value(name)\" --region=us-central1 --limit=1\n",
    "TENSORBOARD_ID = TENSORBOARD_ID[1]\n",
    "IMAGE_NAME = 't5x-base'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'fine-tune-t5-xl'\n",
    "\n",
    "EXPERIMENT_WORKSPACE = f'gs://{BUCKET}/experiments/{EXPERIMENT_NAME}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket definitions\n",
    "VERSION = 'v02'\n",
    "MODEL_NAME = 'finetune-en-de'\n",
    "MODEL_DISPLAY_NAME = f'{MODEL_NAME}-{VERSION}'\n",
    "\n",
    "# Staging bucket for Vertex AI\n",
    "WORKSPACE = f'gs://{BUCKET}/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Docker definitions for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Model dir to save logs, ckpts, etc.\n",
    "MODEL_DIR = f'gs://{BUCKET}/model/{MODEL_DISPLAY_NAME}/{TIMESTAMP}'\n",
    "\n",
    "# Data dir to save the processed dataset\n",
    "TFDS_DATA_DIR = f'gs://{BUCKET}/dataset/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Gin file and run mode\n",
    "GIN_FILE = 'small_finetune_wmt.gin'\n",
    "GIN_FILE_GCS = f'gs://{BUCKET}/staging/{GIN_FILE}'\n",
    "RUN_MODE = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy gin file to GCS bucket and use the local GCSFuse mount\n",
    "! gsutil cp {GIN_FILE} {GIN_FILE_GCS}\n",
    "GIN_FILE_GCS = GIN_FILE_GCS.replace('gs://', '/gcs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Vertex AI client and log metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = f'{MODEL_DISPLAY_NAME}-xl-2-partitions'\n",
    "EXECUTION_NAME = f'execution-1'\n",
    "RUN_NAME = f'run--{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=f'gs://{BUCKET}/staging',\n",
    "    experiment=EXPERIMENT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define infra and submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'cloud-tpu'\n",
    "ACCELERATOR_TYPE = 'TPU_V2'\n",
    "ACCELERATOR_NUM = 32\n",
    "REPLICA_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": REPLICA_COUNT,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"args\": [\n",
    "                f'--run_mode={RUN_MODE}',\n",
    "                f'--gin_file={GIN_FILE_GCS}',\n",
    "                f'--gin.MODEL_DIR=\"{MODEL_DIR}\"',\n",
    "                f'--tfds_data_dir={TFDS_DATA_DIR}',\n",
    "                '--gin.USE_CACHED_TASKS=False'\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 't5x_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir =  os.path.join(WORKSPACE, job_name)\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"\"\"\n",
    "tb-gcp-uploader --tensorboard_resource_name {TENSORBOARD_ID} \\\n",
    "--logdir {MODEL_DIR} \\\n",
    "--experiment_name {EXPERIMENT_ID}\n",
    "\"\"\"\n",
    "\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open the URL presented in the output of this command and analyse the training and inference logs.\n",
    "\n",
    "![Tensorboard](./images/tb-sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Explanations\n",
    "\n",
    "By default, t5x logs many metrics to TensorBoard, many of these seem similar but\n",
    "have important distinctions.\n",
    "\n",
    "The first two graphs you will see are the `accuracy` and `cross_ent_loss`\n",
    "graphs. These are the *token-level teacher-forced* accuracy and cross entropy\n",
    "loss respectively. Each of these graphs can have multiple curves on them. The\n",
    "first curve is the `train` curve. This is calculated as a running sum than is\n",
    "then normalized over the whole training set. The second class of curves have the\n",
    "form `training_eval/${task_name}`. These curves are created by running a subset\n",
    "(controlled by the `eval_steps` parameter of the main train function) of the\n",
    "validation split of `${task_name}` through the model and calculating these\n",
    "metrics using teacher-forcing. These graphs can commonly be used to find\n",
    "\"failure to learn\" cases and as a warning sign of overfitting, but these are\n",
    "often not the final metrics one would report on.\n",
    "\n",
    "The second set of graphs are the ones under the collapsible `eval` section in\n",
    "TensorBoard. These graphs are created based on the `metric_fns` defined in the\n",
    "SeqIO task. The curves on these graphs have the form\n",
    "`inference_eval/${task_name}`. Values are calculated by running the whole\n",
    "validation split through the model in inference mode, commonly auto-regressive\n",
    "decoding or output scoring. Most likely these are the metrics that will be\n",
    "reported.\n",
    "\n",
    "More information about the configuration of the datasets used for these\n",
    "different metrics can be found [here](#train-train-eval-and-infer-eval).\n",
    "\n",
    "In summary, the metric you actually care about most likely lives under the\n",
    "`eval` tab rather, than in the `accuracy` graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
